<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"> 
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
<title>AI Story Editor</title>

<!-- JS & style -->
<link rel="stylesheet" type="text/css" href="../css/style.css?v=2024-07-21">
<script src="../js/functions.js?v=2024-07-21"></script>

<script>

localStorage.setItem('templates',JSON.stringify({
  "Read-write a new story": {
    "prompt": "Produce a JSON object where the key is \"genre\" and the value is ```{{Q1 of 6. What genre does this story belong to (e.g., sci-fi, realistic fiction, romance)?}}```",
    "model": "gpt-4o-mini",
    "temperature": 0,
    "max_tokens": 500,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "Frame",
    "hide_button": false
  },
  "Frame": {
    "prompt": "You are the game master for a table-top role-playing game. You are playing with one other player. They will inhabit the role of the protagonist, making decisions for how they move through the world. You will craft a story around their decisions, providing texture and playing the parts of all the other characters. First, I'm going to give you some context so you understand the narrative expectations. \n\n========\n\nSetting and genre: \n\n- Your story telling should adhere to the following genre expectations: {{Q1 of 6. What genre does this story belong to (e.g., sci-fi, realistic fiction, romance)?}}\n- Your story will start at the following place: {{Q2 of 6. Where does your story take place?}}\n- Your story is set at the following time: {{Q3 of 6. When does your story take place?}}\n\n========\n\nThe Protagonist:\n\nEarlier you asked the other player to fill in a character sheet for the protagonist. Here are their answers. Use them to help you shape the story.\n\n- name: {{Q4 of 6. What is your character's name?}}\n- additional notes: {{Q5 of 6. Anything else I should know that's important to your character (e.g., age, gender, sexual orientation, physical appearance, background)? Keep it brief, and it's okay to say, \"No.\"}}\n\n========\n\nAdditional Notes:\n\nYou also asked them if there was anything else would like you to incorporate into the story. This is what they said: \n\n{{Q6 of 6. Is there anything else you would like me to incorporate into the story? Special \"notes\" you have for this story? Please, keep it short, and it's okay to say, \"No.\"}}\n\n========\n\nStory Arc:\n\nAs the story unfolds you should help shape it to follow this basic structure: \n\n- Section 1 (Exposition): The beginning of the story where the characters, setting, and background information are introduced.\n- Section 2 (Rising Action): The series of events that build tension and develop the conflict. This part of the story usually includes obstacles, challenges, and complications that the characters must face.\n- Section 3 (Climax): The turning point or the highest point of intensity in the story. It is the moment where the conflict reaches its peak, and the outcome is uncertain. The climax often involves a significant decision, confrontation, or revelation.\n- Section 4 (Falling Action): The events that occur after the climax, where the tension starts to decrease. Loose ends are tied up, and the story begins to move towards its resolution.\n- Section 5 (Resolution): The final part of the story where the conflict is resolved, and the loose ends are tied up. It provides closure and answers any remaining questions. The resolution can be either positive or negative, depending on the outcome of the story. \n\n========\n\nStyle:\n\nUnless the other player said otherwise, your prose should be high quality like that you would find in a published book with plenty of dialogue. You avoid repeating yourself and try for a coherent story. You also favor describing events over exposition. You follow the writing advice, show don't tell. \n\n========\n\n\n",
    "model": "",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 7,
    "behavior": "Introduction",
    "hide_button": true
  },
  "Add to story (RPG/protagonist)": {
    "prompt": "{{scratch}}\n",
    "model": "gpt-4o-mini",
    "temperature": 0.7,
    "max_tokens": 1000,
    "output": 0,
    "json_mode": 0,
    "output_to": 4,
    "behavior": "Role Play 01",
    "hide_button": false
  },
  "Introduction": {
    "prompt": "{{scratch}}\n\nGiven the above, write the first two or three paragraphs for the story. Lean heavily into genre expectations. The text should move the story forward and set the stage for the protagonist to take action. The prose should read like that of a novel with plenty of depth and some dialogue. When you're done, I'd like you to return your answer as a JSON object with two key-value pairs. The first key is \"opening\" and its value should be the opening text of the story. The second key is \"title\" and it contains an evocative and appropriate title for the type of story you want to tell. \n\n",
    "model": "gpt-4o",
    "temperature": 0.9,
    "max_tokens": 1000,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "The story begins",
    "hide_button": true
  },
  "The story begins": {
    "prompt": "{{passThrough[\"title\"]}}\n\n{{passThrough[\"opening\"]}}\n\n",
    "model": "",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 6,
    "behavior": "Role Play 01",
    "hide_button": true
  },
  "Role Play 01": {
    "prompt": "{{scratch}}\n\n========\n\nRemember, you are the game master for a table-top role-playing game. Above is the story so far. You are playing with one other player. They inhabit the role of the protagonist, making decisions for how they move through the world. You craft a story around their decisions, providing texture and playing the parts of all the other characters, speaking and acting for them as needed. You ask the player who is playing the protagonist what they want to do next, and this is their answer:\n\n{{What do you want to do next? Answer as the protagonist.*}}\n\n========\n\nTo determine if they are successful, start by assessing the likelihood of success for the above action given what you know about the story so far and the relevant genre conventions. Also, consider what you know of the character's skills and motivations and how those might effect the outcome. That is, figure out how hard it will be for the protagonist to do what they want to. Label this difficulty with one of the following labels: \n\n- Easy\n- Medium\n- Hard\n\nNow we're going to role a 20-sided dice to see if they are successful. Okay, the dice roll was {{d20}}.\n\nIf the difficulty was Easy, the roll ({{d20}}) has to be greater than or equal to 0 for them to succeed. \n\nIf the difficulty was Medium, the roll ({{d20}}) has to be greater than or equal to 4 for them to succeed. \n\nIf the difficulty was Hard, the roll ({{d20}}) has to be greater than or equal to 10 for them to succeed. \n\nReturn a selection of prose, 1 to 2 paragraphs, explaining what happened (i.e., describing what the protagonist did and their success or failure). Be sure to include dialogue when appropriate. The prose should flow naturally from the story so far (text above). Assume that the reader does not know what the player said the protagonist wanted to do. You should include details over generalities. Instead of explaining that something occurred, describe each of the events and actions that took place. Show don't tell! Format your reply in JSON with the following key-value pairs:\n\n1. key=\"difficulty\" and the value is the label you applied above.\n2. key=\"difficulty_cutoff\" and the value is the numeric cutoff for the specified difficulty. \n3. key=\"roll\" and the value is the outcome of the above dice roll.\n4. key=\"success\" and the value is 1 if roll is greater than or equal to the difficulty_cutoff. \n5. key=\"narrative\" and the value is the prose you produce describing what happened.\n\nAnd again, remember to show with your words, don't tell. Walk through events and actions one by one in great detail. Also, if this event seems too much like what has come before, take it in a different direction. Avoid repeating phrases that already appear in the story. Don't hide information in the protagonist's mind. The reader should know everything they do and in detail. \n",
    "model": "gpt-4o-mini",
    "temperature": 0.8,
    "max_tokens": 1000,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "move forward",
    "hide_button": true
  },
  "move forward": {
    "prompt": "{{passThrough[\"narrative\"]}}\n\n",
    "model": "",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 6,
    "behavior": "move forward 2",
    "hide_button": true
  },
  "move forward 2": {
    "prompt": "You're helping write a short story. In a moment I'll give you the text so far, and I want you to add a beat, probably about two or three paragraphs worth, more if it includes dialogue. The text should move the story forward and set the stage for the protagonist to take action. Here's what you have so far: \n\n{{scratch}}\n\n---\n\nWrite the next beat of the story. Be sure to include dialogue when appropriate, and don't try to cram a lot of exposition in, opt instead for setting the protagonist up to take action. Show don't tell. Return your answer as a JSON object where the key is \"next_beat\" and the value what you would like to add to the story. Pay particular attention to all of the story so far to make sure the next beat (this bit) makes sense. \n\n\"next_beat\" should be no more than three paragraphs. It can go two ways: \n\n(1) the section continues and the beat stops after setting the stage for the protagonist to act; or \n\n(2) you decide the section should end because it has done its job as described under the Story Arc. For a section to end, it must have run its course as specified by the Story Arc (e.g., the first section should involve Exposition and the last Resolution). If you think we're at the end of a section, \"next_beat\" should be the beginning of the next section and it should start with \"---\\n\\n,\" where \"\\n\\n\" is a double carriage return. This section break should be followed by an opening paragraph for the new section, setting things up with the section's goal in mind. \n\nIf you're writing a new section (2 above), either change the setting or advance the time to keep things moving. \n\nIf you are continuing the section (1 above), move things towards that section's goals as you understand them, but do NOT jump over any time, place the action directly following the last beat.\n\nEither way, you should move the story forward adding detail and plot points. Make it count. No vague flowery fluff, and make sure your prose follows naturally from the story so far, as described above. Avoid repeating phrases that already appear in the story, and don't use the \"un-Reveal trope\" (i.e., if the reader is promised a secret or introduced to some cryptic plot element, cut to the chase, and reveal the secret or explain the meaning to the reader right away). If you need more space to do this, add a paragraph. Don't hide information in the protagonist's mind. The reader should know everything they do and in detail. This doesn't mean you have to tell us everything they're feeling only what they know.\n",
    "model": "gpt-4o-mini",
    "temperature": 0.8,
    "max_tokens": 1000,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "append 2",
    "hide_button": true
  },
  "append 2": {
    "prompt": "{{passThrough[\"next_beat\"]}}\n\n",
    "model": "",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 6,
    "behavior": "Role Play 01",
    "hide_button": true
  },
  "Add to story (author/narrator)": {
    "prompt": "In a moment, I'm going to show you some background materials used to run a role playing game, followed by the text of how things played out. You're job is to help me add to the story. I'll tell you what to add after I show you the background materials and story so far. Here's what you have so far: \n\n{{scratch}}\n\n---\n\nNow write a few paragraphs continuing the story. Here's what should happen, be sure to include the following:\n\n{{What should happen next? Answer as the narrator.*}}\n\nInclude dialogue when appropriate, and \"Show don't tell.\" \n\nReturn your answer as a JSON object where the key is \"next_beat\" and the value what you would like to add to the story. Pay particular attention to all of the story so far to make sure the next beat (this bit) makes sense.\n\n",
    "model": "gpt-4o-mini",
    "temperature": 0.8,
    "max_tokens": 1000,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "next",
    "hide_button": false
  },
  "next": {
    "prompt": "{{passThrough[\"next_beat\"]}}\n\n",
    "model": "gpt-4o-mini",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 6,
    "behavior": "Add to story (author/narrator)",
    "hide_button": true
  },
  "Shorten selected text": {
    "prompt": "You're a helpful editor and you're going to help trim some text. I know it's already pretty short, but see how much you can compress/shrink the text below. When you rewrite it, knock off at least 20% of the length, but keep the main points: \n\n{{highlighted}}\n",
    "model": "gpt-4o-mini",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": false
  },
  "Embellish selected text": {
    "prompt": "You're a helpful editor and you're going to help flesh out some text. Do your best to expand on the text below by about 20%, keeping the same tone and style. Feel free to makeup and add detail as needed, just keep it consistent with what's already there: \n\n{{highlighted}}\n",
    "model": "gpt-4o-mini",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": false
  },
  "Transform selected text": {
    "prompt": "You're a helpful editor and you're going to help rewrite some text, provided below. Here's what you should do with it. {{What should I do with the selected text?}}: \n\nAnd here's the text itself:\n\n{{highlighted}}",
    "model": "gpt-4o-mini",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": false
  }
}));

//fgnass.github.com/spin.js#v1.2.7
!(function (e, t, n) {
    function o(e, n) {
        var r = t.createElement(e || "div"),
            i;
        for (i in n) r[i] = n[i];
        return r;
    }
    function u(e) {
        for (var t = 1, n = arguments.length; t < n; t++) e.appendChild(arguments[t]);
        return e;
    }
    function f(e, t, n, r) {
        var o = ["opacity", t, ~~(e * 100), n, r].join("-"),
            u = 0.01 + (n / r) * 100,
            f = Math.max(1 - ((1 - e) / t) * (100 - u), e),
            l = s.substring(0, s.indexOf("Animation")).toLowerCase(),
            c = (l && "-" + l + "-") || "";
        return (
            i[o] ||
                (a.insertRule(
                    "@" + c + "keyframes " + o + "{" + "0%{opacity:" + f + "}" + u + "%{opacity:" + e + "}" + (u + 0.01) + "%{opacity:1}" + ((u + t) % 100) + "%{opacity:" + e + "}" + "100%{opacity:" + f + "}" + "}",
                    a.cssRules.length
                ),
                (i[o] = 1)),
            o
        );
    }
    function l(e, t) {
        var i = e.style,
            s,
            o;
        if (i[t] !== n) return t;
        t = t.charAt(0).toUpperCase() + t.slice(1);
        for (o = 0; o < r.length; o++) {
            s = r[o] + t;
            if (i[s] !== n) return s;
        }
    }
    function c(e, t) {
        for (var n in t) e.style[l(e, n) || n] = t[n];
        return e;
    }
    function h(e) {
        for (var t = 1; t < arguments.length; t++) {
            var r = arguments[t];
            for (var i in r) e[i] === n && (e[i] = r[i]);
        }
        return e;
    }
    function p(e) {
        var t = { x: e.offsetLeft, y: e.offsetTop };
        while ((e = e.offsetParent)) (t.x += e.offsetLeft), (t.y += e.offsetTop);
        return t;
    }
    var r = ["webkit", "Moz", "ms", "O"],
        i = {},
        s,
        a = (function () {
            var e = o("style", { type: "text/css" });
            return u(t.getElementsByTagName("head")[0], e), e.sheet || e.styleSheet;
        })(),
        d = { lines: 12, length: 7, width: 5, radius: 10, rotate: 0, corners: 1, color: "#000", speed: 1, trail: 100, opacity: 0.25, fps: 20, zIndex: 2e9, className: "spinner", top: "auto", left: "auto", position: "relative" },
        v = function m(e) {
            if (!this.spin) return new m(e);
            this.opts = h(e || {}, m.defaults, d);
        };
    (v.defaults = {}),
        h(v.prototype, {
            spin: function (e) {
                this.stop();
                var t = this,
                    n = t.opts,
                    r = (t.el = c(o(0, { className: n.className }), { position: n.position, width: 0, zIndex: n.zIndex })),
                    i = n.radius + n.length + n.width,
                    u,
                    a;
                e &&
                    (e.insertBefore(r, e.firstChild || null),
                    (a = p(e)),
                    (u = p(r)),
                    c(r, { left: (n.left == "auto" ? a.x - u.x + (e.offsetWidth >> 1) : parseInt(n.left, 10) + i) + "px", top: (n.top == "auto" ? a.y - u.y + (e.offsetHeight >> 1) : parseInt(n.top, 10) + i) + "px" })),
                    r.setAttribute("aria-role", "progressbar"),
                    t.lines(r, t.opts);
                if (!s) {
                    var f = 0,
                        l = n.fps,
                        h = l / n.speed,
                        d = (1 - n.opacity) / ((h * n.trail) / 100),
                        v = h / n.lines;
                    (function m() {
                        f++;
                        for (var e = n.lines; e; e--) {
                            var i = Math.max(1 - ((f + e * v) % h) * d, n.opacity);
                            t.opacity(r, n.lines - e, i, n);
                        }
                        t.timeout = t.el && setTimeout(m, ~~(1e3 / l));
                    })();
                }
                return t;
            },
            stop: function () {
                var e = this.el;
                return e && (clearTimeout(this.timeout), e.parentNode && e.parentNode.removeChild(e), (this.el = n)), this;
            },
            lines: function (e, t) {
                function i(e, r) {
                    return c(o(), {
                        position: "absolute",
                        width: t.length + t.width + "px",
                        height: t.width + "px",
                        background: e,
                        boxShadow: r,
                        transformOrigin: "left",
                        transform: "rotate(" + ~~((360 / t.lines) * n + t.rotate) + "deg) translate(" + t.radius + "px" + ",0)",
                        borderRadius: ((t.corners * t.width) >> 1) + "px",
                    });
                }
                var n = 0,
                    r;
                for (; n < t.lines; n++)
                    (r = c(o(), {
                        position: "absolute",
                        top: 1 + ~(t.width / 2) + "px",
                        transform: t.hwaccel ? "translate3d(0,0,0)" : "",
                        opacity: t.opacity,
                        animation: s && f(t.opacity, t.trail, n, t.lines) + " " + 1 / t.speed + "s linear infinite",
                    })),
                        t.shadow && u(r, c(i("#000", "0 0 4px #000"), { top: "2px" })),
                        u(e, u(r, i(t.color, "0 0 1px rgba(0,0,0,.1)")));
                return e;
            },
            opacity: function (e, t, n) {
                t < e.childNodes.length && (e.childNodes[t].style.opacity = n);
            },
        }),
        (function () {
            function e(e, t) {
                return o("<" + e + ' xmlns="urn:schemas-microsoft.com:vml" class="spin-vml">', t);
            }
            var t = c(o("group"), { behavior: "url(#default#VML)" });
            !l(t, "transform") && t.adj
                ? (a.addRule(".spin-vml", "behavior:url(#default#VML)"),
                  (v.prototype.lines = function (t, n) {
                      function s() {
                          return c(e("group", { coordsize: i + " " + i, coordorigin: -r + " " + -r }), { width: i, height: i });
                      }
                      function l(t, i, o) {
                          u(
                              a,
                              u(
                                  c(s(), { rotation: (360 / n.lines) * t + "deg", left: ~~i }),
                                  u(c(e("roundrect", { arcsize: n.corners }), { width: r, height: n.width, left: n.radius, top: -n.width >> 1, filter: o }), e("fill", { color: n.color, opacity: n.opacity }), e("stroke", { opacity: 0 }))
                              )
                          );
                      }
                      var r = n.length + n.width,
                          i = 2 * r,
                          o = -(n.width + n.length) * 2 + "px",
                          a = c(s(), { position: "absolute", top: o, left: o }),
                          f;
                      if (n.shadow) for (f = 1; f <= n.lines; f++) l(f, -2, "progid:DXImageTransform.Microsoft.Blur(pixelradius=2,makeshadow=1,shadowopacity=.3)");
                      for (f = 1; f <= n.lines; f++) l(f);
                      return u(t, a);
                  }),
                  (v.prototype.opacity = function (e, t, n, r) {
                      var i = e.firstChild;
                      (r = (r.shadow && r.lines) || 0), i && t + r < i.childNodes.length && ((i = i.childNodes[t + r]), (i = i && i.firstChild), (i = i && i.firstChild), i && (i.opacity = n));
                  }))
                : (s = l(t, "animation"));
        })(),
        typeof define == "function" && define.amd
            ? define(function () {
                  return v;
              })
            : (e.Spinner = v);
})(window, document);


function copy_to_clipboard(text) {
    // Create a temporary textarea element to store the result
    var tempTextArea = document.createElement('textarea');
    tempTextArea.value = text;
  
    // Append the textarea to the document
    document.body.appendChild(tempTextArea);
  
    // Select the text within the textarea
    tempTextArea.select();
  
    // Copy the selected text to the clipboard
    document.execCommand('copy');
  
    // Remove the temporary textarea
    document.body.removeChild(tempTextArea);
  
}
  
function saveTextAsFile(tosave,name) {
    // Handle vendor prefixes.
    window.requestFileSystem = window.requestFileSystem || window.webkitRequestFileSystem;
  
    // tosave = ID of textarea to save
    // name = name to save file as, including file extension     
    // grab the content of the form field and place it into a variable
    var textToWrite = tosave //document.getElementById(tosave).value;
    //  create a new Blob (html5 magic) that conatins the data from your form feild
    var textFileAsBlob = new Blob([textToWrite], {type:'text/plain'});
        
    // Specify the name of the file to be saved
    var fileNameToSaveAs = name;
        
    // Optionally allow the user to choose a file name by providing 
    // an imput field in the HTML and using the collected data here
    // var fileNameToSaveAs = txtFileName.text;
  
    // create a link for our script to 'click'
    var downloadLink = document.createElement("a");
    // supply the name of the file (from the var above).
    // you could create the name here but using a var
    // allows more flexability later.
    downloadLink.download = fileNameToSaveAs;
    // provide text for the link. This will be hidden so you
    // can actually use anything you want.
    downloadLink.innerHTML = "My Hidden Link";
        
    // allow our code to work in webkit & Gecko based browsers
    // without the need for a if / else block.
    window.URL = window.URL || window.webkitURL;
            
    // Create the link Object.
    downloadLink.href = window.URL.createObjectURL(textFileAsBlob);
    // when link is clicked call a function to remove it from
    // the DOM in case user wants to save a second file.
    downloadLink.onclick = destroyClickedElement;
    // make sure the link is hidden.
    downloadLink.style.display = "none";
    // add the link to the DOM
    document.body.appendChild(downloadLink);
        
    // click the new link
    downloadLink.click();
}
  
function destroyClickedElement(event) {
    // remove the link from the DOM
    document.body.removeChild(event.target);
}

function loadFile(filePath) {
    return fetch(filePath)
    .then(response => response.text())
    .then(data => {
        return data
    })
};

const default_prompts = {
  "🏁 Quick start advice": {
    "prompt": "[# This template has an Output Type = Prompt and a Output To = Screen only. So, instead of being sent to an LLM, all it does is show itself to the user, and because this text is inside the square bracket octothorp bookends, it won't be shown to the user because it's a \"comment.\" #]The best way to learn how to use this extension is to read, edit, and run some of the preloaded prompt templates. You can start down this road by clicking the \"Templates & Settings\" button at the bottom of this window.",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 0,
    "behavior": "stop",
    "hide_button": false
  },
  "🌎 Summarize & question this page": {
    "prompt": "{{innerText}} [# FYI, the innerText variable will be replaced with the text from the current active browser tab, and because the Post-run Behavior is set to CHAT, you will be able to continue engaging with this text after the first reply. #]\n  \nProvide a short 150 word summary of the above text. If asked any follow-up questions, use the above text, and ONLY the above text, to answer them. If you can't find an answer in the above text, politely decline to answer explaining that you can't find the information. You can, however, finish a thought you started above if asked to continue, but don't write anything that isn't supported by the above text. And keep all of your replies short! \n",
    "model": "gpt-3.5-turbo-16k",
    "temperature": 0,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": false
  },
  "📖 Define selected word/phrase": {
    "prompt": "Define the following word/phrase: {{highlighted}}[# Here we've set the Output To equal to Screen + append to scratch pad which means that the LLM's output will be appended to the contents of your Scratch Pad, which can be accessed from the Popup by clicking the \"Scratch Pad\" button. #]\n",
    "model": "gpt-3.5-turbo",
    "temperature": 0,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 2,
    "behavior": "stop",
    "hide_button": false
  },
  "📫 Politely decline an email (selected text)": {
    "prompt": "{{highlighted}} [# FYI, the highlighted variable will be replaced with any text you have highlighted/selected when you click the extension's popup, and because Output To is set to Screen + clipboard, the LLMs output will be ready to paste in an email after the interaction runs. #]\n\nThe above is an email. Draft a brief and professional reply politely declining its request. \n",
    "model": "gpt-3.5-turbo-16k",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": false
  },
  "💬 Translate & reply in original language": {
    "prompt": "[# This template's \"big trick\" is that the Post-run Behavior is set to \"display translation and prompt,\" which is the name of another template. This means that after this prompt is run through an LLM, it will trigger \"display translation and prompt,\" and pass to it this template's output. Because the Output To is set to Hidden, however, the user will not see this structured data. #]You are helping translate text into English. Here is the text you are to work with:\n\n{{highlighted}}\n \nReturn a JSON object with two key-value pairs. The first key is called `language`, and its value is the language of the above text. The second key is called `translation`, and its value is the above text translated into English. \n\nNow return the object: \n\n",
    "model": "gpt-3.5-turbo-16k",
    "temperature": 0,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "display translation and prompt",
    "hide_button": false
  },
  "display translation and prompt": {
    "prompt": "Translate the following text into {{passThrough[\"language\"]}}. Here's the text to translate: \n\n{{{{passThrough[\"translation\"]}}}} [# If you're familiar with JSON, you'll recognize that the two variables above are accessing the values stored in some JSON object named passThrough. Namely, the value for \"language\" and \"translation.\" In this way we can very cleanly slice up the output from the prior template. Because the Hide Button checkbox is checked, the user will not see a button for \"display translation and prompt.\" That of course is okay, because it is being triggered by \"Translate & reply in original language.\" #]\n",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "stop",
    "hide_button": true
  },
  "🪄 Magic copy-and-paste": {
    "prompt": "[# What is magic copy-and-paste you ask? Well, its the name I'm giving to text-driven entity extraction. Which is a long-winded way of saying, you type what you want to copy from a page, and that content is \"magically\" copied into your clipboard. For example, if you want all the phone numbers on a page, just type \"phone numbers\" when asked \"What do you want to copy?\" Wait a bit, and presto. There's a list of phone numbers in your clipboard. #]Your job is to create a JSON object from the following Source Text. It should have a single key-value pair. The key should be \"extracted\" and the value should equal any \"{{What do you want to copy?}}\" found in the Source Text. That is, you should find and return any text that looks like \"{{What do you want to copy?}}\" If providing the value calls for a list, separate entries with commas followed by a space, unless the items contain commas, in which case, use semicolons. \n\n---\n\nSOURCE TEXT\n\n{{innerText}}\n\n---\n\nNow provide the JSON object. \n\n",
    "model": "gpt-4",
    "temperature": 0,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "Copy to clipboard",
    "hide_button": false
  },
  "Copy to clipboard": {
    "prompt": "{{passThrough[\"extracted\"]}}[# Again, we're using JSON here to format and cue up our output. #]",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "stop",
    "hide_button": true
  },
  "✍️ \"Diagram\" selected sentence": {
    "prompt": "[# This template is here mostly to show off the JSON parameter (I'm not sure how much I really trust it). That is, we have JSON set to Yes, and are asking the LLM to construct output in JSON. Consequently, the LLM should produce well-structured JSON output. If you haven't seen JSON before, you might want to read up on it here: https://en.wikipedia.org/wiki/JSON. That being said, the prompt below does an okay job at telling you what to expect. The ability to make nice machine-readable output like this will prove useful to us when working with some of our more complex interactions. FWIW, I had ChatGPT create the specifications below. #]Below I will provide you with a string of text. Your job is to produce a JSON representation of its sentence structure. \n\n1. Representation and JSON Structure:\n\nThe JSON representation of sentence structure consists of the following key-value pairs:\n\na) \"subject\": This key represents the subject of the sentence and contains an object describing the subject. The subject object can include properties such as \"type\" (to specify the type of subject, e.g., noun or pronoun) and \"value\" (to store the actual subject word or phrase).\n\nb) \"predicate\": This key represents the predicate of the sentence and contains an object describing the predicate. The predicate object can include properties such as \"type\" (to specify the type of predicate, e.g., verb or verb phrase) and \"value\" (to store the actual predicate word or phrase).\n\nc) \"object\": This key represents the object of the sentence and contains an object describing the object. The object object can include properties such as \"type\" (to specify the type of object, e.g., noun or pronoun) and \"value\" (to store the actual object word or phrase).\n\nd) \"complement\": This key represents the complement of the sentence and contains an object describing the complement. The complement object can include properties such as \"type\" (to specify the type of complement, e.g., adjective or noun phrase) and \"value\" (to store the actual complement word or phrase).\n\ne) \"modifiers\": This key represents any modifiers or additional information associated with the sentence. It contains an array of objects, where each object describes a specific modifier. Each modifier object can include properties such as \"type\" (to specify the type of modifier, e.g., adverbial or prepositional phrase) and \"value\" (to store the actual modifier word or phrase).\n\n2. Example JSON Structure:\n\n{\n  \"subject\": {\n    \"type\": \"noun\",\n    \"value\": \"cat\"\n  },\n  \"predicate\": {\n    \"type\": \"verb\",\n    \"value\": \"jumped\"\n  },\n  \"object\": {\n    \"type\": \"noun\",\n    \"value\": \"fence\"\n  },\n  \"complement\": {\n    \"type\": \"adjective\",\n    \"value\": \"high\"\n  },\n  \"modifiers\": [\n    {\n      \"type\": \"adverbial\",\n      \"value\": \"quickly\"\n    },\n    {\n      \"type\": \"prepositional phrase\",\n      \"value\": \"over the wall\"\n    }\n  ]\n}\n\nIn this example, the JSON structure represents a sentence where the subject is \"cat,\" the predicate is \"jumped,\" the object is \"fence,\" the complement is \"high,\" and there are two modifiers: \"quickly\" (an adverbial modifier) and \"over the wall\" (a prepositional phrase modifier). \n\n3. Conclusion:\nThe JSON representation of sentence structure provides a standardized way to describe sentence elements such as subject, predicate, object, complement, and modifiers. It allows for the structured representation of sentence components, making it easier to process and analyze sentence structures programmatically.\n\nNow that I've given you these specifications, your job is to make such an object for the following text string:\n\n{{highlighted}}\n\nNow provide your JSON object: \n",
    "model": "gpt-3.5-turbo",
    "temperature": 0,
    "max_tokens": 300,
    "output": 1,
    "json_mode": 1,
    "output_to": 1,
    "behavior": "stop",
    "hide_button": false
  },
  "📝 Summarize & question Scratch Pad": {
    "prompt": "{{scratch}} [# This template is just the \"Summarize & question this page\" template with the scratch variable in the place of innerText. Why? Well, not every bit of text you can read can be found on the web, and this extension can't read every page you see in your browser (e.g., PDFs). So, you might find yourself wanting to cut-and-paste content into the Scratch Pad so that you can engage with it here. #]\n  \nProvide a short 150 word summary of the above text. If asked any follow-up questions, use the above text, and ONLY the above text, to answer them. If you can't find an answer in the above text, politely decline to answer explaining that you can't find the information. You can, however, finish a thought you started above if asked to continue, but don't write anything that isn't supported by the above text. And keep all of your replies short!\n",
    "model": "gpt-3.5-turbo-16k",
    "temperature": 0,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": false
  },
  "💾 Save Scratch Pad to file": {
    "prompt": "{{scratch}} [# The scratch variable will be replaced with the content of your Scratch Pad, which can be accessed from the Popup by clicking the \"Scratch Pad\" button. Since we have set the Output Type to Prompt, this prompt will not be sent to an LLM, but having set Post-run Behavior to SAVE TO FILE, it will trigger your browser's save to file action. #]",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 4,
    "behavior": "file",
    "hide_button": false
  },
  "🪙 Coin flip to poem": {
    "prompt": "I'm going to flip a coin. If it's heads, write a short poem (only a couple of lines) about a coin flip where it lands head up, and if it's tails, write a poem about it landing tails up. Be very clear about the result of the coin flip in the poem. \n\nCoin flip: {{coinFlip}} [# The value of {{coinFlip}} is random, or as \"random.\" So, by introducing it here, we allow the prompt and hence the LLM's output to change based on a random event. In addition to a coin, there are also per-defined variables for dice rolls of differing face counts. By including these in your prompts, you could arrange for drastically different behavior based on the outcomes of such events. Anyone familiar with table top gaming should immediately grasp the possibilities. #]\n\nNow give me your response/poem: \n",
    "model": "gpt-3.5-turbo",
    "temperature": 0.9,
    "max_tokens": 163,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "stop",
    "hide_button": false
  },
  "🗜️ Shorten selected text": {
    "prompt": "You're a helpful editor and you're going to help trim some text. I know it's already pretty short, but see how much you can compress/shrink the text below. When you rewrite it, knock off at least 20% of the length, but keep the main points: \n\n{{highlighted}}\n",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": false
  },
  "🔬 Expand selected (short) text": {
    "prompt": "[# This template is the first in a chain of templates that can either end or loop back on itself. It works by getting the LLM to generate some dialog and send that along with text the user has highlighted to another template. That template takes an action and feeds into another template, and so on and so on. Note: we're using gpt-3.5-turbo-1106 as a model here and in some of the subsequent templates in this chain. When this model is retired it will break things and require updating. #]You are an actor playing the role of a helpful writing assistant. In this scene you will interact with a writer. You will ask them some questions about some copy they are working on. You're goal is to ask them enough question such that their answers can be used to expand on the existing text. That is, you want them to give you things one could use to expand on the existing text. As this is a dialogue, we will present it in the form of a transcript. The writer will start by reading what they have so far. \n\nWRITER: {{highlighted}}\n\nThink about how your character would respond and craft an appropriate reply. You will provide the text of this reply along with one other piece of information as a JSON object. The object will have two key-value pairs. The first key-value pair's key is \"transcript\" and the value is that of the transcript above, starting with \"WRITER:\" and followed by the text of their copy. Be sure to escape an quotation marks. The second key-value pair has a key called \"reply\" and its value is the response you crafted above (i.e., it is the text of your character's reply to the above, your first question for the writer). Include only the text of your reply (e.g., do NOT preface the text with the name of the speaker).\n",
    "model": "gpt-3.5-turbo-1106",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "Expand Text 1",
    "hide_button": false
  },
  "Expand Text 1": {
    "prompt": "{{passThrough[\"transcript\"]}}\nYOU: {{passThrough[\"reply\"]}}\nWRITER: {{{{passThrough[\"reply\"]}}*}} [# Here we've encased {{passThrough[\"reply\"]}} inside a set of curly brackets. Imagine {{passThrough[\"reply\"]}} has the value \"What made you think that?\" Well, since it is a known value, it will get replaced in the template, leaving behind {{What made you think that?}}. However, this is not a known value. So the user will be asked \"What made you think that?\" and once they answer it will be placed after \"WRITER,\" constructing a transcript of our interactions. Why the asterisk? It's a way to force user input. Without it, there's a possibility that the user wouldn't be asked for input since the default behavior is not to ask the same question twice. Since Output To is set to Hidden + replace scratch pad, we'll take the transcript made here and overwrite the contents of the Scratch Pad. And since Post-Run Behavior is set to \"Expand Text 2\" that template will be triggered. #]\n",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 7,
    "behavior": "Expand Text 2",
    "hide_button": true
  },
  "Expand Text 2": {
    "prompt": "[# This template looks very much like the first in our chain, except it pulls from the Scratch Pad and feeds into \"Expand Text 3.\" #] You are an actor playing the role of a helpful writing assistant. In this scene you will interact with a writer. You are asks them questions about some copy they are working on. You're goal is to ask them enough question such that their answers can be used to expand on the existing text. That is, you want them to give you things one could use to expand on the existing text. As this is a dialogue, we will present it in the form of a transcript. The writer began by reading the copy they have so far. \n\n{{scratch}}\n\nThink about how your character would respond and craft an appropriate reply. You will provide the text of this reply along with one other piece of information as a JSON object. The object will have two key-value pairs. The first key-value pair's key is \"transcript\" and the value is that of the transcript above, starting with \"WRITER:\" the text of their copy and the subsequent questions and answers. Be sure to escape an quotation marks. And DO NOT repeat yourself (i.e., ask new questions). The second key-value pair has a key called \"reply\" and its value is the response you crafted above (i.e., it is the text of your character's reply to the above, your question for the writer). Make sure it's a question. Include only the text of your reply (e.g., do NOT preface the text with the name of the speaker). \n",
    "model": "gpt-3.5-turbo-1106",
    "temperature": 0.7,
    "max_tokens": 2000,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "Expand Text 3",
    "hide_button": true
  },
  "Expand Text 3": {
    "prompt": "YOU: {{passThrough[\"reply\"]}}\nWRITER: {{{{passThrough[\"reply\"]}}*}} [# Here unlike \"Expand Text 1\" we append to, rather than overwrite, the Scratch Pad, meaning we just add to the transcript before passing things on to \"Expand Text 4.\" Again we place an asterisk before the closing curly brackets to force user input. #]\n",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 6,
    "behavior": "Expand Text 4",
    "hide_button": true
  },
  "Expand Text 4": {
    "prompt": "[# This looks a lot like \"Expand Text 2,\" but since it uses the Post-run Behavior DYNAMIC, it can trigger different templates based on the contents of the transcript (i.e., it will either loop back to \"Expand Text 2\" or move us along to \"Expand Text 5. #]You are an actor playing the role of a helpful writing assistant. In this scene you will interact with a writer. You are asks them questions about some copy they are working on. You're goal is to ask them enough question such that their answers can be used to expand on the existing text. That is, you want them to give you things one could use to expand on the existing text. As this is a dialogue, we will present it in the form of a transcript. The writer began by reading the copy they have so far. \n\n{{scratch}}\n\nYou will provide a JSON object in response to the above with a key named `next`. In your role as a writing assistant, consider if there is enough material in the above transcript to pad the original copy by 20%. You probably need at least three or four rounds of Q&A. However, if the replies are light on content, you may need more. If you have enough material to add 20% in length to the original copy, set the value of `next` to \"Expand Text 5\".  Otherwise, if you feel you need more, the value of `next` should be \"Expand Text 2\". \n",
    "model": "gpt-3.5-turbo-1106",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 1,
    "output_to": 4,
    "behavior": "pass",
    "hide_button": true
  },
  "Expand Text 5": {
    "prompt": "[# Having collected more context from the user, we're now ready to produce some new text and copy that to the clipboard (Output To = Screen + clipboard). #]You are a helpful writing assistant. You've just had a conversation with a writer about some copy they're working on, and your task is to take what you learned from that conversation and rewrite the original copy such that its about 20% longer. Here's the text of your conversation. The writer began by reading the copy they have so far.\n\n{{scratch}}\n\nUse what you learned above to rewrite the original copy, adding details learned above. Do your best to keep the writer's voice and style while adding relevant details from your conversation to that first entry. Do NOT embellish! Do NOT make things up! Keep your additions firmly based on the content of your conversation, and don't make your copy too long! You goal is simply to flesh out the original text (i.e., the writer's first utterance above), adding about 20% in length. That being said, provide your new longer copy below.\n",
    "model": "gpt-3.5-turbo-16k",
    "temperature": 0.7,
    "max_tokens": 1000,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": true
  },
  "😡 Anger Translator (for reply to selected)": {
    "prompt": "[# Select some text you want to reply to for context and then give your best angry reply. The LLM will then attempt to make it more palatable. #]You are an \"anger translator.\" Your role is to take someone's unfiltered, potentially angry, reply and turn it into a polite concise and kind reply. That is, you turn angry or blunt text into a respectful not angry version. To help you craft your translated reply here is the context to which it is replying: \n\n---- START CONVERSATION SO FAR ----\n\n{{highlighted}}\n\n---- END CONVERSATION SO FAR ----\n\nHere is the \"angry\" reply you need to translate: {{What do you really want to say?}}\n\n---\n\nNow reply with your translation. \n\n",
    "model": "gpt-3.5-turbo-16k",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "chat",
    "hide_button": false
  },
  "🤖 🐂 💩 BS with a \"bot\"": {
    "prompt": "{{Yes?}} [# {{Yes?}} isn't a predefined variable. So, the user will be presented with a text input, and since Post-run Behavior is set to CHAT, this ends up being a plain old chat with an LLM. #]\n",
    "model": "gpt-3.5-turbo-16k",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 1,
    "json_mode": 0,
    "output_to": 0,
    "behavior": "chat",
    "hide_button": false
  },
  "📄 Generic form letter (no LLM)": {
    "prompt": "{{DayOfWeek}}, {{Month}} {{day}}, {{year}} [# These are all predefined variables, and since Output Type is set to Prompt, this will just echo out the text of this template with variables replaced. #]\n\n{{Who is this letter addressed to?}}:\n\n[This is where you ({{What's your name?}}) should put the text of your boilerplate letter.] \n\nSincerely, \n{{What's your name?}} [# Note: The user is only presented with \"What's your name?\" once because the default behavior is not to repeat user prompts. If you added an asterisk before the closing brackets, however, it would force user input. #]",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 1,
    "behavior": "stop",
    "hide_button": false
  },
  "🎲 🎲 Variables \"random outcomes\" and \"time\"": {
    "prompt": "When building your prompts, consider using some of these preloaded variables. \n\nRandom Outcomes: \n\n- Coin Flip: {{coinFlip}}\n- D4 (1-4): {{d4}} \n- D6 (1-6): {{d6}}\n- D8 (1-8): {{d8}}\n- D% (0-9): {{d%}}\n- D20 (1-20): {{d20}}\n\nBrowser Date and Time:\n\n- Day of week (0-6): {{dayOfWeek}}\n- Day of week (English): {{DayOfWeek}}\n- Month (1-12): {{month}}\n- Month (01-12): {{month2d}}\n- Month (English): {{Month}}\n- Day of Month (0-31): {{day}}\n- Day of Month (01-31): {{day2d}}\n- Year: {{year}}\n- Hour (1-12): {{hours}}\n- Hour (01-12): {{hours2d}}\n- Hour (0-23): {{hours24}}\n- Hour (00-23): {{hours242d}}\n- AM or PM: {{ampm}}\n- Minute (0-59): {{minutes}}\n- Minute (00-59): {{minutes2d}}\n- Second (0-59): {{seconds}}\n- Second (00-59): {{seconds2d}}\n- All together: \n\nIt is {{hours}}:{{minutes2d}}:{{seconds2d}} {{ampm}} on {{DayOfWeek}}, {{Month}} {{day}}, {{year}}",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 0,
    "behavior": "stop",
    "hide_button": false
  },
  "🔍 Variables \"from this page\"": {
    "prompt": "When building your prompts, consider using text from the current webpage, be it selected/highlighted text or the whole page. For example...\n\nPage Data: \n\n- Highlighted words: {{nSelectedWords}}\n- Highlighted text: {{highlighted}}\n- Page words: {{nWordsOnPage}}\n- innerText of page: {{innerText}}",
    "model": "gpt-3.5-turbo",
    "temperature": 0.7,
    "max_tokens": 250,
    "output": 0,
    "json_mode": 0,
    "output_to": 0,
    "behavior": "stop",
    "hide_button": false
  }
}
  
  localStorage.setItem('default_templates', JSON.stringify(default_prompts));
  
  if (localStorage.templates) {
      templates = JSON.parse(localStorage.templates)
  } else {
      localStorage.setItem('templates', JSON.stringify(default_prompts));
      templates = JSON.parse(JSON.stringify(default_prompts))
  }


// START ENCRYPTION 
// adapted from https://raw.githubusercontent.com/bradyjoslin/webcrypto-example/master/script.js
const buff_to_base64 = (buff) => btoa(
  new Uint8Array(buff).reduce(
      (data, byte) => data + String.fromCharCode(byte), ''
      )
  );
  
  const base64_to_buf = (b64) =>
      Uint8Array.from(atob(b64), (c) => c.charCodeAt(null));
  
  const enc = new TextEncoder();
  const dec = new TextDecoder();
  
  const getPasswordKey = (password) =>
      window.crypto.subtle.importKey("raw", enc.encode(password), "PBKDF2", false, [
      "deriveKey",
      ]);
  
  const deriveKey = (passwordKey, salt, keyUsage) =>
      window.crypto.subtle.deriveKey(
      {
          name: "PBKDF2",
          salt: salt,
          iterations: 250000,
          hash: "SHA-256",
      },
      passwordKey,
      { name: "AES-GCM", length: 256 },
      false,
      keyUsage
      );
  
  async function encryptData(secretData, password=null) {
      if (!password) {
          password = window.prompt("Password");
      }
      try {
      const salt = window.crypto.getRandomValues(new Uint8Array(16));
      const iv = window.crypto.getRandomValues(new Uint8Array(12));
      const passwordKey = await getPasswordKey(password);
      const aesKey = await deriveKey(passwordKey, salt, ["encrypt"]);
      const encryptedContent = await window.crypto.subtle.encrypt(
          {
          name: "AES-GCM",
          iv: iv,
          },
          aesKey,
          enc.encode(secretData)
      );
  
      const encryptedContentArr = new Uint8Array(encryptedContent);
      let buff = new Uint8Array(
          salt.byteLength + iv.byteLength + encryptedContentArr.byteLength
      );
      buff.set(salt, 0);
      buff.set(iv, salt.byteLength);
      buff.set(encryptedContentArr, salt.byteLength + iv.byteLength);
      const base64Buff = buff_to_base64(buff);
      return base64Buff;
      } catch (e) {
      console.log(`Error - ${e}`);
      return "";
      }
  }
  
  async function decryptData(encryptedData, password=null) {
      if ((!password) && (!sessionStorage.pwd)) {
        password = window.prompt("Password");
      } else if (sessionStorage.pwd) {
        password = sessionStorage.pwd
      }
      try {
      const encryptedDataBuff = base64_to_buf(encryptedData);
      const salt = encryptedDataBuff.slice(0, 16);
      const iv = encryptedDataBuff.slice(16, 16 + 12);
      const data = encryptedDataBuff.slice(16 + 12);
      const passwordKey = await getPasswordKey(password);
      const aesKey = await deriveKey(passwordKey, salt, ["decrypt"]);
      const decryptedContent = await window.crypto.subtle.decrypt(
          {
          name: "AES-GCM",
          iv: iv,
          },
          aesKey,
          data
      );
      sessionStorage.pwd = password;
      return dec.decode(decryptedContent);
      } catch (e) {
      console.log(`Error - ${e}`);
      alert("Key decryption failed. Reload page to try again, or continue, and enter a new key when prompted.")
      return "";
      }
  }
  // END ENCRYPTION 
//
// Load defaults
//

if (localStorage.api_key) {
  api_key = localStorage.api_key
} else {
  api_key = ""
  localStorage.setItem('api_key',api_key)
}

// user decrypt
if (localStorage.api_key=="") {
    (async () => {
        api_key = await decryptData("Wky0qurBodVqo1bcYuWd44yeBNqj0krAwoE/QDGV82U1CBfKfUOI6sR+zreeinlVH3eTPHWQHVl/rwcOisk5/xvImtM24FAxqBT2NTHb7ofsqVEcOK7i7GQ3lzFILLOXDHa00Q==","General")
    })()
}

if (localStorage.api_base) {
  api_base = localStorage.api_base
} else {
  api_base = "https://api.openai.com/v1/chat/completions"
  localStorage.setItem('api_base',api_base)
}

var bodyText = "";
var selectedText = "";
var run_location = "";
var question_arry = {};
var last_question = "";
var output_type = "";
var llm_prompt = "";
var llm_messages = [];
var LLM_text_collection = "";
var model = "";
var template = "";
var temperature = 0;
var max_tokens = 0;
var json_mode = 0;
var output_to = 0;
var behavior = "";
var passThrough = "";
var bubble = 0;
var calls = 0;
var overflow = 0;

popup_CSS = `* {
  box-sizing: border-box;
}

input:focus, textarea {
  outline: none;
}

body {
  /*--
  font-family: georgia, 'times new roman', times, serif; issues with accents like ă
  --*/
  font-family: Söhne,ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif,Helvetica Neue,Arial,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;
  box-sizing: border-box;
}

#scratch_pad {
  box-sizing: border-box;
  width:100%;
  height:100%;
  padding:20px;
  border:0px solid #ccc;
  resize: none;
  overflow-y: auto;
}

.text_wrap{
  float:left;
  width:100%;
  margin:0;
  padding:0;
}

.input_text {
  float:right;
  font-size: 16px;
  line-height: 20px;
  margin: 0px 5px 15px 0;
  max-width:100%;
  margin-left:20%;
  background:#eee;
  border-radius:8px;
  padding:15px;
}

.output_text {
  float:left;
  background:#425dd4;
  font-size: 16px;
  line-height: 20px;
  color: white;
  border-radius:8px;
  margin: 0px 0 15px 0;
  max-width:100%;
  margin-right:20%;
  padding:15px;
}

code {
  background:#2c3e8e;
}

.code_wrapper {
  padding:3px;
  margin: 0px;
  width:100%;
  overflow-x: auto;
  background:#2c3e8e;
}

.msg_text {
  float:left;
  font-family: Verdana, Geneva, sans-serif;
  font-variant: small-caps;
  width:100%;
  text-align: center;
  font-size: 14px;
  color:#7d7878;
  margin:0 0 15px 0;
}`

//
// General functions
//

function start_spinner(target_id) {
  var opts = {
    lines: 13, // The number of lines to draw
    length: 7, // The length of each line
    width: 4, // The line thickness
    radius: 10, // The radius of the inner circle
    corners: 1, // Corner roundness (0..1)
    rotate: 0, // The rotation offset
    color: '#909090', // #rgb or #rrggbb
    speed: 1, // Rounds per second
    trail: 60, // Afterglow percentage
    shadow: false, // Whether to render a shadow
    hwaccel: false, // Whether to use hardware acceleration
    className: 'spinner', // The CSS class to assign to the spinner
    zIndex: 2e9, // The z-index (defaults to 2000000000)
    top: '15', // Top position relative to parent in px
    left: '0' // Left position relative to parent in px
  };
  var target = document.getElementById(target_id);
  var spinner = new Spinner(opts).spin(target);
}

document.addEventListener('DOMContentLoaded', function () {

  var myButton = document.getElementById('send');
  myButton.addEventListener('click', function() {
    submit_text();
  });  

  var myChatAns = document.getElementById('chat_user_input');
  myChatAns.addEventListener('keydown', submitChatOnEnter);  

  var myChatButton = document.getElementById('chat_send');
  myChatButton.addEventListener('click', function() {
    submit_chat_text();
  });    

  var myContinueButton = document.getElementById('continueButton');
  myContinueButton.addEventListener('click', function() {
    submit_continue();
  });    

  var toPromptButton = document.getElementById('toPrompt');
  toPromptButton.addEventListener('click', function() {
    choose_prompt();
  });

  var credentialsButton = document.getElementById('credentialsButton');
  credentialsButton.addEventListener('click', function() {
    saveAPICred();
  });

  document.getElementById("api_base").addEventListener("keydown", saveOnEnter);
  document.getElementById("api_key").addEventListener("keydown", saveOnEnter);

  var mySettings = document.getElementById('config');
  mySettings.addEventListener('click', function() {
    window.open("options.html", 'options').focus();
  });

  var myScratch = document.getElementById('scratch');
  myScratch.addEventListener('click', function() {
    window.open("scratch.html", 'scratch').focus();
  });

  var myAbout = document.getElementById('about');
  myAbout.addEventListener('click', function() {
    window.open("https://github.com/SuffolkLITLab/prompts", '_projectPage').focus();
  });

  var myFeedback = document.getElementById('feedback');
  myFeedback.addEventListener('click', function() {
    window.open("https://github.com/SuffolkLITLab/prompts/issues", '_logIssues').focus();
  });

  var save_transcript = document.getElementById('save_transcript');
  save_transcript.addEventListener('click', function() {
      const d = new Date();
      const day_list = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'];
      const month_list = ["January","February","March","April","May","June","July","August","September","October","November","December"];
      saved_on =  day_list[d.getDay()] + ", " + month_list[d.getMonth()] + " " + d.getDate() + ", " + d.getFullYear();

      transcript_html = "<html>\n<head>\n<title>Transcript: "+ saved_on +"</title><style>\n"+popup_CSS+"\n</style>\n</head>\n<body>\n";
      transcript_html += document.getElementById('transcript').innerHTML;
      transcript_html += "<div class='msg_text'>Saved "+saved_on+" at " + (d.getHours() % 12 || 12) + ":" + ('0' + d.getMinutes()).slice(-2) + " " + (d.getHours() >= 12 ? 'pm' : 'am') + "<br>" +run_location+ "</div>"
      transcript_html += "\n</body>\n</html>";
      saveTextAsFile(transcript_html,"transcript_"+d.getFullYear()+"-"+('0'  + d.getMonth()).slice(-2)+"-"+('0'  + d.getDate()).slice(-2)+"T"+('0'  + d.getHours()).slice(-2)+('0' + d.getMinutes()).slice(-2)+('0'  + d.getSeconds()).slice(-2)+".html")
  });

  document.getElementById("restartButton").addEventListener("click", function() {
    location.reload();
  });

  document.getElementById("restartButton_companion").addEventListener("click", function() {
    location.reload();
  });

  document.getElementById("restartButton_companion_chat").addEventListener("click", function() {
    location.reload();
  });


  if (!localStorage.scratch_pad) {
    localStorage.setItem('scratch_pad',"")
  } else {
     document.getElementById('scratch_pad').value = localStorage.scratch_pad
  }  

  var BORDER_SIZE = 8;
      
  let m_pos;
  function resize(e,disable=0){
    if (disable!=1) {
      if (window.innerWidth>=458) {
        const dx = m_pos - e.x;
        m_pos = e.x;
        panel_width = parseInt(getComputedStyle(panel, '').width)
        if (panel_width<180) {
          panel_width = 181;
        } else if ((window.innerWidth-panel_width)< 90) {
          panel_width = window.innerWidth - 91;
        }
        panel.style.width = (panel_width + dx) + "px";
        panel_l.style.right = (panel_width + dx) + "px";
        localStorage.panel_w = (panel_width + dx);  
      } else {
        panel.style.width = "100%"
        panel_l.style.right = "100%"
      }
    }
  }

  if (window.innerWidth>=458) {
    panel_width = localStorage.panel_w
    if ((panel_width=="100%") & (window.getComputedStyle(document.getElementById("inline_scratch"), null).display =="none")) {
      document.getElementById("main_wrapper").style.width = "100%"
      document.getElementById("inline_scratch").style.right = "100%"  
    } else if (panel_width>(window.innerWidth-80)) {
      document.getElementById("main_wrapper").style.width =  "50%"
      document.getElementById("inline_scratch").style.right = "50%"
    } else if (panel_width>0) {
      document.getElementById("main_wrapper").style.width = localStorage.panel_w + "px";
      document.getElementById("inline_scratch").style.right = (parseInt(localStorage.panel_w)) + "px";
    } else {
      if (window.getComputedStyle(document.getElementById("inline_scratch"), null).display =="none") {
        document.getElementById("main_wrapper").style.width = "100%"
        document.getElementById("inline_scratch").style.right = "100%"    
      } else {
        panel_width = 450;
        localStorage.panel_w = panel_width
        document.getElementById("main_wrapper").style.width = localStorage.panel_w + "px";
        document.getElementById("inline_scratch").style.right = (parseInt(localStorage.panel_w)) + "px";  
      }
    }
  } else {
    document.getElementById("main_wrapper").style.width = "100%"
    document.getElementById("inline_scratch").style.right = "100%"
    localStorage.panel_w = "100%"
  }

  var panel = document.getElementById("main_wrapper");
  panel.addEventListener("mousedown", function(e){
    if (e.offsetX < BORDER_SIZE) {
      m_pos = e.x;
      document.addEventListener("mousemove", resize, false);
    }
  }, false);
  
  var panel_l = document.getElementById("inline_scratch");
  document.addEventListener("mouseup", function(){
      document.removeEventListener("mousemove", resize, false);
  }, false);

  // Save text to localStorage on change
  document.getElementById('scratch_pad').addEventListener('input', function() {
    localStorage.setItem('scratch_pad', this.value);
    current_text = this.value;
  });

});

//
// Construct, submit, and handel prompts
//

function choose_prompt(choice) {

  calls+=1;
  console.log("Choosing template: "+choice)
  console.log("Runs w/o interaction: "+calls)

  if (calls>=20) {
    if (confirm(`Are you in a loop? You've made 20 prompt calls without human interaction. Choose "OK" to continue or "Cancel" to stop here.`) == true) {
      calls = 0;
    } else {
      insert_restart();
    }
  }

  if (calls<20) {

    output_type = templates[choice]["output"]
    template = templates[choice]["prompt"];
    model = templates[choice]["model"];
    max_tokens = templates[choice]["max_tokens"]; // How long the answer should be 
    temperature = templates[choice]["temperature"]; // How free-ranging the reply is 0-1 
    json_mode = templates[choice]["json_mode"];
    output_to = templates[choice]["output_to"];
    behavior = templates[choice]["behavior"];

    llm_prompt = template

    // remove comments
    llm_prompt = llm_prompt.replace(/\[\#[\s\S]*?\#\]/g, "");

    if (llm_prompt){
      abandon_prompt = 0;
      // Place selected text into template
      if (selectedText=="" && template.match(/{{highlighted}}/g)) {
        console.log("Unable to find highlighted/selected text for this page.");
        if (confirm('Unable to find highlighted/selected text for this page. Choose "OK" to continue with an empty value or "Cancel" to stop this template.') == true) {
          llm_prompt = llm_prompt.replace(/{{highlighted}}/g, ""); 
          llm_prompt = llm_prompt.replace(/{{nSelectedWords}}/g, 0); 
        } else {
          abandon_prompt = 1;
        }
      } else {
        if (selectedText.length>0) {
          llm_prompt = llm_prompt.replace(/{{highlighted}}/g, selectedText.replace(/({|})/g, "\\$1")); 
          try {
            llm_prompt = llm_prompt.replace(/{{nSelectedWords}}/g, selectedText.match(/\b(\w+)\b/g).length);             
          } catch (error) {
            llm_prompt = llm_prompt.replace(/{{nSelectedWords}}/g, "unknown");    
          }
        } else {
          llm_prompt = llm_prompt.replace(/{{highlighted}}/g, ""); 

          llm_prompt = llm_prompt.replace(/{{nSelectedWords}}/g, 0); 
        }
      }

      if (abandon_prompt == 0) {
        // Place page text into template
        if (bodyText=="" && template.match(/{{innerText}}/g)) {
          console.log("Unable to parse innerText for this page.");
          if (confirm('Unable to parse innerText for this page. Choose "OK" to continue with an empty value or "Cancel" to stop this prompt.') == true) {
            llm_prompt = llm_prompt.replace(/{{innerText}}/g, "");
            llm_prompt = llm_prompt.replace(/{{nWordsOnPage}}/g, 0);
          } else {
            abandon_prompt = 1;
          }
        } else {
          if (bodyText.length>0) {
            llm_prompt = llm_prompt.replace(/{{innerText}}/g, bodyText.replace(/({|})/g, "\\$1"));
            try {
              llm_prompt = llm_prompt.replace(/{{nWordsOnPage}}/g, bodyText.match(/\b(\w+)\b/g).length);              
            } catch (error) {
              llm_prompt = llm_prompt.replace(/{{nWordsOnPage}}/g, "unknown");       
            }
          } else {
            llm_prompt = llm_prompt.replace(/{{innerText}}/g, "");
            llm_prompt = llm_prompt.replace(/{{nWordsOnPage}}/g, 0);
          }
        }
      }

    } else {
      alert(`Can't read prompt. `)
      abandon_prompt = 1;

    }

    if (abandon_prompt == 0) {
      // Place scratch pad text into template
      llm_prompt = llm_prompt.replace(/{{scratch}}/g, localStorage.getItem('scratch_pad'));
      try {
        console.log("Attempting to parse Scratch Pad for JSON...")
        scratch = JSON.parse(localStorage.getItem('scratch_pad').trim());
      } catch (error) {
        console.log("Scratch Pad isn't JSON.")
      }
      var scratchjson = llm_prompt.match(/{{scratch\["[a-zA-Z_-]+"\]}}/g);
      // Loop through each variable and present it as a question
      if (scratchjson) {
        console.log("Checking scratch...");
        for (item of scratchjson) {
            key = [...item.matchAll(/{{scratch\["([a-zA-Z_]+)"\]}}/g)][0][1];
            console.log(" - scratch[\""+key+"\"]="+scratch[key]);
            llm_prompt = llm_prompt.replace("{{scratch[\""+key+"\"]}}", scratch[key]);  
        }
      }
      
      if (passThrough.constructor === ({}).constructor) {
        llm_prompt = llm_prompt.replace(/{{passThrough}}/g, JSON.stringify(passThrough));
      } else {
        llm_prompt = llm_prompt.replace(/{{passThrough}}/g, passThrough);
      }
      var passThroughjson = llm_prompt.match(/{{passThrough\["[a-zA-Z_-]+"\]}}/g);
      // Loop through each variable and present it as a question
      if (passThroughjson) {
        console.log("Checking passThrough...");
        for (item of passThroughjson) {
            key = [...item.matchAll(/{{passThrough\["([a-zA-Z_]+)"\]}}/g)][0][1];
            console.log(" - passThrough[\""+key+"\"]="+passThrough[key]);
            llm_prompt = llm_prompt.replace("{{passThrough[\""+key+"\"]}}", passThrough[key]);  
        }
      }

      // ------------------------------------------------------
      // Add predefined variables to the the template
      // ------------------------------------------------------
    
      // Coin
      flip = Math.floor(Math.random() * 2)
      flip_out = ["heads","tails"]
      llm_prompt = llm_prompt.replace(/{{coinFlip}}/g,flip_out[flip]);
      // Dice 
      roll = Math.floor(Math.random() * 4) + 1
      llm_prompt = llm_prompt.replace(/{{d4}}/g,roll);
      roll = Math.floor(Math.random() * 6) + 1
      llm_prompt = llm_prompt.replace(/{{d6}}/g,roll);
      roll = Math.floor(Math.random() * 8) + 1
      llm_prompt = llm_prompt.replace(/{{d8}}/g,roll);
      roll = Math.floor(Math.random() * 10)
      llm_prompt = llm_prompt.replace(/{{d%}}/g,roll);
      roll = Math.floor(Math.random() * 12) + 1
      llm_prompt = llm_prompt.replace(/{{d12}}/g,roll);
      roll = Math.floor(Math.random() * 20) + 1
      llm_prompt = llm_prompt.replace(/{{d20}}/g,roll);

      // Dates 
      const d = new Date();
      const day_list = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'];
      llm_prompt = llm_prompt.replace(/{{dayOfWeek}}/g, d.getDay()); // number
      llm_prompt = llm_prompt.replace(/{{DayOfWeek}}/g, day_list[d.getDay()]); // english
      const month_list = ["January","February","March","April","May","June","July","August","September","October","November","December"];
      llm_prompt = llm_prompt.replace(/{{month}}/g, d.getMonth()); // number
      llm_prompt = llm_prompt.replace(/{{month2d}}/g, ('0'  + d.getMonth()).slice(-2)); // number
      llm_prompt = llm_prompt.replace(/{{Month}}/g, month_list[d.getMonth()]); // english
      llm_prompt = llm_prompt.replace(/{{day}}/g, d.getDate()); // day of month
      llm_prompt = llm_prompt.replace(/{{day2d}}/g, ('0'  + d.getDate()).slice(-2)); // day of month
      llm_prompt = llm_prompt.replace(/{{year}}/g, d.getFullYear()); // YEAR
      llm_prompt = llm_prompt.replace(/{{hours24}}/g, d.getHours()); // hours (out of 24)
      llm_prompt = llm_prompt.replace(/{{hours242d}}/g, ('0'  + d.getHours()).slice(-2)); // hours (out of 24)
      llm_prompt = llm_prompt.replace(/{{hours}}/g, (d.getHours() % 12 || 12)); // hours (out of 12)
      llm_prompt = llm_prompt.replace(/{{hours2d}}/g, ('0'  + (d.getHours() % 12 || 12)).slice(-2)); // hours (out of 12)
      llm_prompt = llm_prompt.replace(/{{ampm}}/g, d.getHours() >= 12 ? 'pm' : 'am');
      llm_prompt = llm_prompt.replace(/{{minutes}}/g, d.getMinutes());
      llm_prompt = llm_prompt.replace(/{{minutes2d}}/g, ('0'  + d.getMinutes()).slice(-2));
      llm_prompt = llm_prompt.replace(/{{seconds}}/g, d.getSeconds());
      llm_prompt = llm_prompt.replace(/{{seconds2d}}/g, ('0'  + d.getSeconds()).slice(-2));

      if (llm_prompt.trim()=="") {
        alert(`Error: Empty prompt. `)
        abandon_prompt = 1;
      } else {
        build_prompt();
      }
      
    }
  }

}

function scroll2Q(id) {
  document.getElementById('save_transcript').style.display='block';

  if (bubble>0) {
    var top = document.getElementById(id).offsetTop; //Getting Y of target element
    console.log("Jump to Y for ("+id+"): "+top);
    //adapted from https://github.com/Yappli/smooth-scroll
    moving_frequency = 0.75
    var getScrollTopDocumentAtBegin = document.getElementById('inner_wrapper').scrollTop + document.body.scrollTop;
    console.log("Y:",top,getScrollTopDocumentAtBegin)
    var hop_count = Math.round((top - getScrollTopDocumentAtBegin)/moving_frequency)
    var gap = (top - getScrollTopDocumentAtBegin) / hop_count;
    for(var i = 1; i <= hop_count; i++)
        {
          (function()
            {
              var hop_top_position = gap*i;
                setTimeout(function(){  document.getElementById('inner_wrapper').scrollTo(0, hop_top_position + getScrollTopDocumentAtBegin); }, moving_frequency*i);
              })();
        }
  }
}

function build_prompt() {
  console.log("Building prompt...");
  LLM_text_collection = "";
      
  // Make a list of all other variables (i.e. text of the form {{variable}}). 
  var questions = llm_prompt.match(/{{[^}]+}}/g)

  console.log("Questions:",questions)
  document.getElementById('button_list').style.display='none';
  document.getElementById('transcript').style.display='block';

  // Loop through each variable and present it as a question
  if (questions) {
    for (question of questions) {
      last_question = question;
      if ((!question_arry[question]) || (question.match(/\*}}$/))) {
        question_ = question.replace(/\*}}$/,"}}")
        question_ = question_.replace(/{|}/g,"");
        if (document.getElementById('thinking_box').style.display=="block") {
          setTimeout(() => {
            document.getElementById('thinking_box').style.display='none';
            document.getElementById('text_input').style.display='block';
            document.getElementById('user_input').focus();
            bubble+=1;
            document.getElementById('output_window').innerHTML += "<div class='text_wrap' id='text_"+bubble+"'><div class='output_text'>"+question_+"</div></div>";
            scroll2Q("text_"+bubble);
            document.getElementById("user_input").addEventListener("keydown", submitOnEnter);
          }, 300);        
        } else {
          document.getElementById('thinking_box').style.display='none';
          document.getElementById('text_input').style.display='block';
          document.getElementById('user_input').focus();
          bubble+=1;
          document.getElementById('output_window').innerHTML += "<div class='text_wrap' id='text_"+bubble+"'><div class='output_text'>"+question_+"</div></div>";
          scroll2Q("text_"+bubble);
          document.getElementById("user_input").addEventListener("keydown", submitOnEnter);
        }
        break
      } else {
        llm_prompt = llm_prompt.replaceAll(last_question,question_arry[last_question]);
        build_prompt(0);
        break
      }
    }
  } else {

    document.getElementById('thinking_box').style.display='block';

    // Count the words in the prompt
    words = llm_prompt.match(/\b(\w+)\b/g).length;
    characters = llm_prompt.length;
    token_est = Math.round(words*1.75)

    console.log("Words in prompt: "+words+" (~"+token_est+" tokens)\nMODEL: "+model+"\nPROMPT:\n\n"+llm_prompt)

    if (output_type==1) {
      console.log("Mode: Calling LLM")
      openai_call(llm_prompt)
    } else {
      console.log("Mode: Prompt only")
      after_build(llm_prompt)
    }
    
  }
}

function submit_text() {
  
  answer =  document.getElementById('user_input').value;
  if (answer.length>0) {
    console.log("Sending text...")
    calls=0;
    document.getElementById('text_input').style.display='none'
    document.getElementById('thinking_box').style.display='block';
    bubble+=1;
    document.getElementById('output_window').innerHTML += "<div class='text_wrap' id='text_"+bubble+"'><div class='input_text'>"+answer+"</div></div>";
    scroll2Q("text_"+bubble);
    llm_prompt = llm_prompt.replaceAll(last_question, answer);
    question_arry[last_question] = answer;
    console.log("Q: "+question_+"\nA: "+answer);
    document.getElementById('user_input').value = "";
    build_prompt(0);  
  } else {
    alert("You cannot leave this input blank.");
    document.getElementById('user_input').focus();
  }
}

function saveAPICred() {
  localStorage.setItem("api_base",document.getElementById('api_base').value)
  localStorage.setItem("api_key",document.getElementById('api_key').value)
  document.getElementById('credentials').style.display='none';
  document.getElementById('output_window').innerHTML += "<div class='msg_text'>credentials saved</div>";
  insert_restart();
}

function saveOnEnter(event) {
  if (event.which === 13) {
      if (!event.repeat) {
        saveAPICred()
      }
      event.preventDefault(); // Prevents the addition of a new line in the text field
  }
}

function submitOnEnter(event) {
  if (!event.shiftKey && event.which === 13) {
      if (!event.repeat) {
        submit_text();
      }
      event.preventDefault(); // Prevents the addition of a new line in the text field
  }
}

function submit_chat_text() {
  answer =  document.getElementById('chat_user_input').value;
  if (answer.length>0) {
    console.log("Sending text...")
    calls=0;
    document.getElementById('chat_text_input').style.display='none'
    document.getElementById('thinking_box').style.display='block';
    bubble+=1;
    document.getElementById('output_window').innerHTML += "<div class='text_wrap' id='text_"+bubble+"'><div class='input_text'>"+answer+"</div></div>";
    scroll2Q("text_"+bubble);
    document.getElementById('chat_user_input').value = "";
    openai_call(answer)  
  } else {
    alert("You cannot leave this input blank.");
    document.getElementById('user_input').focus();
  }
}

function submitChatOnEnter(event) {
  if (!event.shiftKey && event.which === 13) {
      if (!event.repeat) {
        submit_chat_text();
      }
      event.preventDefault(); // Prevents the addition of a new line in the text field
  }
}

function submit_continue() {
  console.log("Sending continue request...")
  calls=0;
  document.getElementById('continue_gen').style.display='none';
  document.getElementById('thinking_box').style.display='block';
  openai_call("You got cutoff. Pickup where you left off and continue.")  
}

async function openai_call(prompt_text) {

  var xhr = new XMLHttpRequest();
  xhr.open("POST", api_base);

  xhr.setRequestHeader("Content-Type", "application/json");
  xhr.setRequestHeader("Authorization", "Bearer "+api_key);

  xhr.onreadystatechange = function () {
     if (xhr.readyState === 4) {
      try {
        console.log(xhr.responseText);
        LLM_text = JSON.parse(xhr.responseText)["choices"][0]["message"]["content"];
        llm_messages.push({"role": "assistant", "content": LLM_text})
        after_build(LLM_text, JSON.parse(xhr.responseText)["choices"][0]["finish_reason"]);
        console.log("BEHAVIOR:"+behavior)
        if ((behavior!="chat") && (behavior!="next")) { 
          llm_messages = []  
        }

      } catch (error) {
        llm_messages.pop();
        try {
          if (JSON.parse(xhr.responseText)["error"]["code"]=="context_length_exceeded") {
            est_token_limit = [...JSON.parse(xhr.responseText)["error"]["message"].matchAll(/\d+/g)]
            keep_n = Math.floor((est_token_limit[0] - max_tokens)/2);
            if (llm_messages.length==0) {
              console.log("ERROR: The prompt and its expected reply exceeds the token limit for this model.");
              LLM_text = "ERROR: The prompt and its expected reply exceeds the token limit for this model."
              output_to=0;
              behavior="stop"
              after_build(LLM_text)

            } else {
              console.log("ERROR: Over the course of this chat, you have reached the token limit for this model.");
              LLM_text = "ERROR: Over the course of this chat, you have reached the token limit for this model."
              output_to=0;
              behavior="stop"
              after_build(LLM_text)

            }
          } else if ((output_type==1) & (json_mode==1) & (JSON.parse(xhr.responseText)["error"]["message"].includes("response_format"))) {
            console.log("Removing json flag, trying again...")
            json_mode = 2;
            openai_call(prompt_text);
          } else {
            LLM_text = `There was an ERROR calling the LLM. Make sure you are using a valid endpoint and API Key. The credentials may have expired, or the model used by this tools' author my have been retired.`
            output_to=0;
            behavior="stop"
            //LLM_text += "\n"+error            
            after_build(LLM_text);
            document.getElementById('restartButton').style.display='none';
            document.getElementById('credentials').style.display='block';
            document.getElementById('api_base').value = localStorage.api_base || "https://api.openai.com/v1/chat/completions";
            document.getElementById('api_key').value = localStorage.api_key || "";
            document.getElementById('api_key').focus();
          }            
        } catch (error) {
          LLM_text = `There was an ERROR calling the LLM. Make sure you are using a valid endpoint and API Key. The credentials may have expired, or the model used by this tools' author my have been retired.`
          output_to=0;
          behavior="stop"
          //LLM_text += "\n"+error            
          after_build(LLM_text)
          document.getElementById('restartButton').style.display='none';
          document.getElementById('credentials').style.display='block';
          document.getElementById('api_base').value = localStorage.api_base || "https://api.openai.com/v1/chat/completions";
          document.getElementById('api_key').value = localStorage.api_key || "";
          document.getElementById('api_key').focus();
      }
      }
    }};


  llm_messages.push({"role": "user", "content": prompt_text})
  var data = {
            "model": model, 
            "messages": llm_messages,
            "temperature": temperature,
            "max_tokens": max_tokens
          };

  if (json_mode==1) {
    console.log("Attempting JSON mode");
    if (localStorage.api_base.includes('#lmstudio')) {
      data["response_format"]= {
        "type": "json_schema",
        "json_schema": {
          "name": "llm_response",
          "strict": "true",
          "schema": {
            "type": "object",
            "properties": {}
          }
        }
      }
      if (prompt_text.startsWith(`Produce a JSON object where the key is \"genre\"`)) {
        data["response_format"]["json_schema"]["schema"]["properties"] = {
          "genre": {
            "type": "string"
          }
        }
        data["response_format"]["json_schema"]["schema"]["required"] = ["genre"]
      } else if (prompt_text.endsWith(`\"title\" and it contains an evocative and appropriate title for the type of story you want to tell. \n\n`)) {
        data["response_format"]["json_schema"]["schema"]["properties"] = {
          "opening": {
            "type": "string"
          },
          "title": {
            "type": "string"
          } 
        }
        data["response_format"]["json_schema"]["schema"]["required"] = ["title","opening"]
      } else if (prompt_text.endsWith(`Don't hide information in the protagonist's mind. The reader should know everything they do and in detail. \n`)) {
        data["response_format"]["json_schema"]["schema"]["properties"] = {
          "difficulty": {
            "type": "string"
          },
          "difficulty_cutoff": {
            "type": "integer"
          },
          "roll": {
            "type": "integer"
          },
          "success": {
            "type": "integer"
          },
          "narrative": {
            "type": "string"
          }
        }
        data["response_format"]["json_schema"]["schema"]["required"] = ["difficulty","difficulty_cutoff","roll","success","narrative"]
      } else if (prompt_text.startsWith(`You're helping write a short story. `)) {
        data["response_format"]["json_schema"]["schema"]["properties"] = {
          "next_beat": {
            "type": "string"
          }
        }
        data["response_format"]["json_schema"]["schema"]["required"] = ["next_beat"]
      } else if (prompt_text.startsWith(`In a moment, I'm going to show you some background materials used to run a role playing game, followed by the text of how things played out.`)) {
        data["response_format"]["json_schema"]["schema"]["properties"] = {
          "next_beat": {
            "type": "string"
          }
        }
        data["response_format"]["json_schema"]["schema"]["required"] = ["next_beat"]
      }     
    } else {
      data["response_format"]={ "type": "json_object" }  
    }           
  }

  console.log(data);

  return xhr.send(JSON.stringify(data));    
  
}


function accountForHTML(str) {
  return String(str).replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;').replace(/"/g, '&quot;');
}

function insert_restart(){
  document.getElementById('restartButton').style.display='block';
  document.getElementById("restartButton").focus(); 
}

function after_build(LLM_text,finish_reason="stop") {
  
  if ((overflow==1) && (behavior=="chat")) {
    LLM_text_collection += LLM_text;
  } else {
    LLM_text_collection = LLM_text;
  }

  // add line breaks for screen output
  LLM_text_formatted = accountForHTML(LLM_text);
  LLM_text_formatted = LLM_text_formatted.replaceAll(/```([^`]*)```\n?/g, "<pre class='code_wrapper'><code>$1</code></pre>");
  LLM_text_formatted = LLM_text_formatted.replaceAll(/`([^`]*)`/g, "<code>$1</code>");
  LLM_text_formatted = LLM_text_formatted.trim();
  document.getElementById('thinking_box').style.display='none';

  // If not hidden
  if (output_to<4) {
    bubble+=1;
    document.getElementById('output_window').innerHTML += "<div class='text_wrap' id='text_"+bubble+"'><div class='output_text' style='white-space: pre-wrap;'>"+LLM_text_formatted+"</div></div>";
    scroll2Q("text_"+bubble);
  }

  // Check on json formatting
  if (json_mode>=1) {
    console.log("Attempting to parse JSON...")
    try {
      passThrough = JSON.parse(LLM_text_collection.trim());
      LLM_text_collection = JSON.stringify(passThrough, null, 2);        
    } catch (error) {
      alert("Warning: Output isn't JSON. Leaving as is! This may cause issues.")
      passThrough = LLM_text_collection;     
    }
  } else {
    passThrough = LLM_text_collection;
  }

  output_words = LLM_text_collection.match(/\b(\w+)\b/g).length;
  output_characters = LLM_text_collection.length;

  // Output location
  if (output_to==1) {
    document.getElementById('output_window').innerHTML += "<div class='msg_text'>above output copied to clipboard (~"+output_words.toLocaleString()+" words / ~"+output_characters.toLocaleString()+" characters)</div>";
    copy_to_clipboard(LLM_text_collection);
  } else if (output_to==2) {
    document.getElementById('scratch_pad').value += LLM_text_collection;
    document.getElementById('output_window').innerHTML += "<div class='msg_text'>above output appended to scratch pad (~"+output_words.toLocaleString()+" words / ~"+output_characters.toLocaleString()+" characters)</div>";
    localStorage.setItem('scratch_pad', localStorage.getItem('scratch_pad')+LLM_text); // used LLM_text, not LLM_text_collection because will have already been appended
  } else if (output_to==3) {
    document.getElementById('scratch_pad').value = LLM_text_collection;
    document.getElementById('output_window').innerHTML += "<div class='msg_text'>above output replaced scratch pad (~"+output_words.toLocaleString()+" words / ~"+output_characters.toLocaleString()+" characters)</div>";
    localStorage.setItem('scratch_pad', LLM_text_collection);
  } else if (output_to==5) {
    //document.getElementById('output_window').innerHTML += "<div class='msg_text'>above output copied to clipboard</div>";
    copy_to_clipboard(LLM_text_collection);
  } else if (output_to==6) {
    document.getElementById('scratch_pad').value += LLM_text_collection;
    //document.getElementById('output_window').innerHTML += "<div class='msg_text'>above output appended to scratch pad</div>";
    localStorage.setItem('scratch_pad', localStorage.getItem('scratch_pad')+LLM_text); // used LLM_text, not LLM_text_collection because will have already been appended
  } else if (output_to==7) {
    document.getElementById('scratch_pad').value = LLM_text_collection;
    //document.getElementById('output_window').innerHTML += "<div class='msg_text'>above output replaced scratch pad</div>";
    localStorage.setItem('scratch_pad', LLM_text_collection);
  } 
  
  // Behavior

  overflow=0;

  if ((finish_reason=="length") && (behavior=="chat")) {
    overflow=1;
    document.getElementById('continue_gen').style.display='block';
    calls=0;
    scroll2Q("text_"+bubble); 

  } else if (behavior=="stop") {
    // End
    //document.getElementById('output_window').innerHTML += "<div class='msg_text'>end</div>";
    calls=0;
    insert_restart();
    scroll2Q("text_"+bubble); 

  } else if (behavior=="chat") {
    // Continue chat
    //document.getElementById('output_window').innerHTML += "<div class='msg_text'>engage with the above</div>";
    document.getElementById('chat_text_input').style.display='block';
    document.getElementById('chat_user_input').focus();
    calls=0;
    scroll2Q("text_"+bubble); 

  } else if (behavior=="file") {
    // Save to file
    document.getElementById('output_window').innerHTML += "<div class='msg_text'>triggered save to file</div>";
    calls=0;
    insert_restart();
    scroll2Q("text_"+bubble); 
    saveTextAsFile(LLM_text_collection,"output.txt")

  } else if (behavior=="pass") {
    // passThrough
    if (passThrough["next"]){
      try {
        choose_prompt(passThrough["next"])        
      } catch (error) {
        alert('No matching prompt found for "'+passThrough["next"]+'." Defaulting to FULL STOP')
        //document.getElementById('output_window').innerHTML += "<div class='msg_text'>end</div>";          
        calls=0;
        insert_restart();
        scroll2Q("text_"+bubble); 
      }
    } else {
      alert('No value found for passThrough["next"] defaulting to FULL STOP')
      //document.getElementById('output_window').innerHTML += "<div class='msg_text'>end</div>";
      calls=0;
      insert_restart();
      scroll2Q("text_"+bubble); 
    }

  } else {
    // Run another prompt
    choose_prompt(behavior)

  }

}

// Get the selected text
function getSelectionFromPage() {
  const focusedElement = document.activeElement;

  if (focusedElement) {
    if (focusedElement.tagName.toLowerCase() === 'textarea' || focusedElement.tagName.toLowerCase() === 'input') {
      if (typeof focusedElement.selectionStart === 'number' && typeof focusedElement.selectionEnd === 'number') {
        selectedText = focusedElement.value.substring(focusedElement.selectionStart, focusedElement.selectionEnd);
      } else if (focusedElement.selectionStart === undefined) {
        // For input elements in some browsers like Firefox
        const selection = focusedElement.value.substring(
          focusedElement.selectionStart, focusedElement.selectionEnd
        );
        if (selection) {
          selectedText = selection;
        }
      }
    }
  }
  let body_text = document.getElementById('scratch_pad').value;

  try {
    let run_location = window.location.toString();    
  } catch (error) {
    let run_location = "location unknown";
  }

  console.log(selectedText,body_text,run_location)

  return [selectedText,body_text,run_location]
}

document.addEventListener('DOMContentLoaded', function () {
  templates = JSON.parse(localStorage.templates)
  const buttonList = document.getElementById('button_list');

  //templates.forEach(function(item, index) {
  for (const [key, value] of Object.entries(templates)) {

    if (templates[key]["hide_button"]==false) {
      // Create button element
      const button = document.createElement('button');
      button.textContent = key; // Set button text
      button.id = `template_`+key.replace(/[^a-zA-Z]/g,"_"); // Set button id
      button.dataset.choice = key; // Set data-choice attribute
      button.style.width = '100%'; // Set styles
      button.style.marginBottom = '5px';

      // Add event listener to button
      button.addEventListener('mousedown', function() {
        text_arry = getSelectionFromPage(); selectedText = text_arry[0]; bodyText = text_arry[1];
      });
      button.addEventListener('click', function() {
        choose_prompt(this.dataset.choice); // 'this' refers to the button clicked
      });

      // Append button to button list in DOM
      buttonList.appendChild(button);
    }

  };

  start_spinner('thinking');

});

window.onbeforeunload = function () {
  document.getElementById('inner_wrapper').scrollTo(0, 0);
}

document.addEventListener('DOMContentLoaded', function() {
        
  var open_scratch = document.getElementById('open_scratch');
  document.getElementById('open_scratch').addEventListener('click', function() {
      if (confirm('This will replace the current scratch pad contents with the file you upload. Choose "OK" to continue or "Cancel" to keep things as they are.') == true) {
          document.getElementById('fileInput').click(); // Trigger file input
      }
  });
  document.getElementById('fileInput').addEventListener('change', function(event) {
      const file = event.target.files[0];
      if (!file) {
          return;
      }

      const reader = new FileReader();
      reader.onload = function(e) {
          const contents = e.target.result;
          try {
              document.getElementById('scratch_pad').value = contents
              localStorage.setItem('scratch_pad', contents);
              //const json = JSON.parse(contents);
              //updatePromptsFromJson(json); // Function to update prompts
          } catch (error) {
              console.error("Error reading file: ", error);
              // Handle errors (invalid file, etc.)
          }
      };
      reader.readAsText(file);
  });

  var save_scratch = document.getElementById('save_scratch');
  save_scratch.addEventListener('click', function() {
      saveTextAsFile(document.getElementById('scratch_pad').value,"my_story.txt")
  });

});
</script>
<style>
	* {
		box-sizing: border-box;
	}

	input:focus, textarea {
		outline: none;
	}
	
	body {
		font-family: Söhne,ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif,Helvetica Neue,Arial,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;
		box-sizing: border-box;
	}

	#send {
		float:left;
		width:75%;
		margin: 5px 0 0px 0;
	}

	#chat_send {
		float:left;
		width:75%;
		margin: 5px 0 0px 0;
	}

	#restartButton_companion {
		float:right;
		width:24%;
		margin: 5px 0 10px 0;
	}

	#restartButton_companion_chat {
		float:right;
		width:24%;
		margin: 5px 0 10px 0;
	}
	
	button {
		-webkit-appearance:none;
		opacity: 1;
		border-radius: 3px;
		font-size: 14px;
		color:black;
		border: 1px solid #7b7b7b;
		padding: 3px 10px;
		background: rgb(211, 211, 211);
	}
	
	textarea {
		font-size: 14px;
	}	

	.file_menu {
		border-bottom: 1px solid #eee;
		padding-left: 5px;
	}

	a.files {
		font-size: 14px;
		line-height: 25px;
		text-decoration: none;
		color: darkblue;
	}

  .dark-mode a.files {
    color: #88e3ff;
  }

	.scratch_frame{
		position: absolute;
		top:25px;
		bottom:5px;
		left:0px;
		right:0px;
	}

	#scratch_pad {
		box-sizing: border-box;
		width:100%;
		height:100%;
		padding:20px;
		border:0px solid #ccc;
		resize: none;
		overflow-y: auto;
	}

	.text_wrap{
		float:left;
		width:100%;
		margin:0;
		padding:0;
	}

	.input_text {
		float:right;
		font-size: 15px;
		line-height: 20px;
		margin: 0px 5px 15px 0;
		max-width:100%;
		margin-left:20%;
		background:#eee;
		border-radius:8px;
		padding:15px;
	}

	.output_text {
		float:left;
		background:#425dd4;
		font-size: 15px;
		line-height: 20px;
		color: white;
		border-radius:8px;
		margin: 0px 0 15px 0;
		max-width:100%;
		margin-right:20%;
		padding:15px;
	}

	code {
		background:#2c3e8e;
	}

	.code_wrapper {
		padding:3px;
		margin: 0px;
		width:100%;
		overflow-x: auto;
		background:#2c3e8e;
	}

	.msg_text {
		float:left;
		font-family: Verdana, Geneva, sans-serif;
		font-variant: small-caps;
		width:100%;
		text-align: center;
		font-size: 14px;
		color:#7d7878;
		margin:0 0 15px 0;
	}

	/* -- the below is needed for interactions -- */

	#button_list {
		min-height:150px;
		margin-bottom: 3px;
	}

	#thinking_box{
		float:left;
		width:100%;
		display:none;
	}

	#thinking {
		width:43px;
		height:75px;
		margin:0 auto;
	}

	#user_input{
		width:100%;
		height:50px;
	}

	#chat_user_input{
		width:100%;
		height:50px;
	}

	#continue_gen {
		float:left;
		width:100%;
		margin: 0px 0 10px 0;
	}

	#continueButton{
		width:100%;
	}

	#credentials {
		float:left;
		width:100%;
		margin: 0px 0 10px 0;
	}

	#credentials_table{
		width:100%;
		margin: 0 0 5px 0;
	}

	#credentialsButton{
		width:100%;
	}

	#restartButton{
		display:none;
		width:100%;
		margin: 0 0 10px 0;
	}

	#save_transcript{
		display:none;
		float:left;
		font-family: Verdana, Geneva, sans-serif;
		font-variant: small-caps;
		width:100%;
		text-align: center;
		font-size: 14px;
		color:#7d7878;
		margin:0 0 15px 0;
	}

	/*-- The below differes between export and non --*/

	.custom_header{
		margin: 0 0 10px 0;
	}

	#inline_scratch {
		position: absolute;
		top: 0px;
		bottom: 0px;
		left: 0px;
		right: 346px;
		overflow: hidden;
	}

	#main_wrapper{
		position: absolute;
		padding: 0 0px 0 18px;
		top: 0px;
		bottom: 0px;
		right: 0px;
		width:39%;
		overflow-y: auto;
	}
	
	#main_wrapper::after {
		content: '';
		position: absolute;
		top: 0;
		left: 0;
		bottom: 0;
		width: 8px;
		background: #ccc;
		cursor: ew-resize;
		display: inline-block;
	}

	#inner_wrapper{
		height:100%;
		width:100%;
		overflow-y: scroll;
		padding: 0 10px 0 0;
	}

	.footer {
		display:none;
	}

  .dark-mode #scratch_pad {
    background: #333;
  }

	@media only screen and (max-width: 450px) {
		
		#inline_scratch {
			position: absolute;
			top: 0px;
			height: 50vh;
			width: 100%;
			left: 0px;
			right: 0px;
			overflow-y: auto;
			border-bottom: solid 1px #7d7878;
		}
		
		#main_wrapper{
			position: absolute;
			padding: 0 10px 0 10px;
			top: 50vh;
			width: 100%;
			bottom: 0px;
			left: 0px;
			right: 0px;
			overflow-y: auto;
		}

		#main_wrapper::after {
			display:none;
		}

		#inner_wrapper{
			position: relative;
			height:100%;
			width:100%;
			overflow-y: scroll;
			padding: 0;
		}
	
	}
</style>
</head>
<body>
  <div id="inline_scratch">
    <div class="file_menu">
      <a href="../" id="back_home" class="files">&laquo; Home</a> |  
      <a href="#" id="open_scratch" class="files">Open</a> |  
      <input type="file" id="fileInput" style="display: none;"/>
      <a href="#" id="save_scratch" class="files">Save</a>   
    </div>
    <div class="scratch_frame">
      <textarea id="scratch_pad" placeholder="This space holds text for use with the prompt interactions found on the other half of the screen."></textarea>
    </div>
  </div> 
  <div id="main_wrapper">
    <div id="inner_wrapper">
      <!--
        START CUSTOM CONTENT
      -->
      <div class="custom_header">
        <h2 style="margin-top: 10px;">AI Story Editor</h2>
        <p>
          This page operates much like the Library's <a href="../">home page</a>, allowing you to read-write a story by playing the part of the protagonist, serving as what we call a <a href="../tips">reader-author</a>. You can, however, shift the balance more towards the author side or work directly on selected text. Whatever your choice, your story will show up below the framing text we first use to <a href="../about">prompt the LLM</a>. 
        </p>
        <hr>
      </div>
      <!--
        END CUSTOM CONTENT
      -->
      <div id="button_list"></div>
      <div id="transcript" style="display:none;">
        <div id="output_window"></div>
      </div>
      <div id="thinking_box">
        <div id="thinking"></div>
      </div>
      <div id="text_input" style="display:none;">
        <textarea id="user_input"></textarea>
        <button id="send">Send</button>
        <button id="restartButton_companion">Menu</button>
      </div>
      <div id="chat_text_input" style="display:none;">
        <textarea id="chat_user_input"></textarea>
        <button id="chat_send" >Send</button>
        <button id="restartButton_companion_chat">Menu</button>
      </div>
      <div id="continue_gen" style="display:none;">
        <button id='continueButton'>Continue text generation</button>
      </div>
      <a href="#" id="save_transcript">save transcript</a>
      <button id="restartButton">Menu</button>
      <div id="credentials" style="display:none;">
        <table id="credentials_table">
          <tr><td>API&nbsp;Base:&nbsp;</td><td width="100%"><input id="api_base" style="width:100%"></td></tr>
          <tr><td>API&nbsp;Key:&nbsp;</td><td width="100%"><input id="api_key" style="width:100%"></td></tr>
        </table>        
        <button id='credentialsButton'>Update/Save Credentials</button>
      </div>
      <div id="choices" style="display:none;">
        <select id="toPrompt" style="width:100%;margin:5px 0 8px 0;text-align:center;">
          <option value="">Pass output to prompt (choose one)</option>
        </select>
      </div>
    </div>
  </div>
  <div class="footer">
    <button id="config">Templates &amp; Settings</button>
    <button id="scratch">Scratch Pad</button>
    <span style="float:right">
      <button id="about">About</button>
      <button id="feedback">Feedback</button>
    </span>
  </div>
</body>
</html>